{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class ViolaJones:\n",
    "    def __init__(self, T = 10):\n",
    "        self.clfs = []\n",
    "        self.T = T  #T: The number of weak classifiers which should be used\n",
    "        self.alphas = []\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filename):\n",
    "        with open(filename+\".pkl\", 'rb') as f:\n",
    "            return pickle.load(f)    \n",
    "\n",
    "    def train(self, training, pos_num, neg_num):\n",
    "        training_data = []\n",
    "        weights = np.zeros(len(training))\n",
    " \n",
    "        for i in range(len(training)):\n",
    "            label = training[i][1]\n",
    "            img = training[i][0]\n",
    "            integral_img = (integral_image(img), label)\n",
    "            training_data.append(integral_img)\n",
    "            \n",
    "            if label == 1:\n",
    "                temp = (2 * pos_num)\n",
    "                weights[i] = 1.0 / temp\n",
    "            else:\n",
    "                temp = (2 * neg_num)\n",
    "                weights[i] = 1.0 / temp\n",
    "\n",
    "       \n",
    "        img_0 = training_data[0][0]\n",
    "        i = 0\n",
    "        n = 0\n",
    "        if len(img_0):\n",
    "            n = 1\n",
    "        features = self.get_features(img_0.shape)\n",
    "\n",
    "        \n",
    "        X = np.zeros((len(features), len(training_data)))\n",
    "        y = np.array(list(map(lambda data: data[1], training_data)))\n",
    "        \n",
    "        for f in features:\n",
    "            if len(f):\n",
    "                n = n+1\n",
    "            \n",
    "            feature = lambda inte_img: sum([pos.compute_feature(inte_img) for pos in f[0]]) - sum([neg.compute_feature(inte_img) for neg in f[1]])\n",
    "            if(n):\n",
    "                n = n+1\n",
    "            X[i] = list(map(lambda data: feature(data[0]), training_data))\n",
    "            i += 1\n",
    "\n",
    "        # Selecting best features\n",
    "        top = SelectPercentile(f_classif, percentile=10)\n",
    "        cl = top.fit(X.T, y)\n",
    "        ind = cl.get_support(indices=True)\n",
    "        features = features[ind]\n",
    "        X = X[ind]\n",
    "        \n",
    "      \n",
    "        for t in range(self.T):\n",
    "            norm = np.linalg.norm(weights)\n",
    "            weights = weights / norm\n",
    "            weak_classifiers = self.train_weak(X, y, features, weights)\n",
    "            clf, error, accuracy = self.top(weak_classifiers, weights, training_data)\n",
    "            er = (1.0 - error)\n",
    "            beta = error / er\n",
    "            for i in range(len(accuracy)):\n",
    "                temp = (beta ** (1 - accuracy[i]))\n",
    "                weights[i] = weights[i] * temp\n",
    "            al = 1.0/beta\n",
    "            alpha = math.log(al)\n",
    "            self.alphas.append(alpha)\n",
    "            self.clfs.append(clf)\n",
    "            # print(\"Chose classifier: %s with accuracy: %f and alpha: %f\" % (str(clf), len(accuracy) - sum(accuracy), alpha))\n",
    "\n",
    "    def train_weak(self, X, y, features, weights):\n",
    "        \"\"\"\n",
    "        Finds the optimal threshs for each weak classifier given the current weights\n",
    "        \"\"\"\n",
    "        classifiers = []\n",
    "        total_pos = 0\n",
    "        total_neg = 0\n",
    "        for i in range(len(y)):\n",
    "            if y[i] == 1:\n",
    "                total_pos = total_pos + weights[i]\n",
    "            else:\n",
    "                total_neg = total_neg + weights[i]\n",
    "\n",
    "        \n",
    "        total_features = X.shape[0]\n",
    "        for i in range(len(X)):\n",
    "            applied_feature = sorted(zip(weights, X[i], y), key=lambda x: x[1])\n",
    "\n",
    "            pos_visited = 0\n",
    "            neg_visited = 0\n",
    "            pos_weights = 0\n",
    "            neg_weights = 0\n",
    "\n",
    "            min_error = float('inf')\n",
    "            best_feature = None\n",
    "            best_thresh = None\n",
    "            best_polarity = None\n",
    "\n",
    "            for j in range(len(applied_feature)):\n",
    "            \n",
    "                er1 = neg_weights + total_pos - pos_weights\n",
    "                er2 = pos_weights + total_neg - neg_weights\n",
    "                error = min(er1, er2)\n",
    "\n",
    "                if error < min_error:\n",
    "                    min_error = error\n",
    "                    best_feature = features[index]\n",
    "                    best_thresh = applied_feature[j][1]\n",
    "                    if pos_visited > neg_visited:\n",
    "                        best_polarity = 1\n",
    "                    else:\n",
    "                        best_polarity = -1\n",
    "\n",
    "                if applied_feature[j][2] == 1:\n",
    "                    pos_weights = pos_weights + applied_feature[j][0]\n",
    "                    pos_visited = pos_visited + 1\n",
    "                    \n",
    "                else:\n",
    "                    neg_weights = neg_weights + applied_feature[j][0]\n",
    "                    neg_visited = neg_visited + 1\n",
    "                    \n",
    "            classifiers.append(Classifier_weak(best_feature[0], best_feature[1], best_thresh, best_polarity))\n",
    "        return classifiers\n",
    "      \n",
    "        \n",
    "    def classify(self, image):\n",
    "        total = 0\n",
    "        for i in range(len(self.alphas)):\n",
    "            total = total + self.alphas[i] * self.clfs[i].classify(integral_image(image))\n",
    "        p = 0\n",
    "        temp =  0.5 * sum(self.alphas)\n",
    "        if(temp>0):\n",
    "            p += 1\n",
    "            \n",
    "        if total <= temp:\n",
    "            return 0\n",
    "        return 1\n",
    "   \n",
    "\n",
    "    def top(self, classifiers, weights, training_data):\n",
    "        best_clf = None\n",
    "        best_error = float('inf')\n",
    "        best_accuracy = None\n",
    "\n",
    "        for i in range(len(classifiers)):\n",
    "            \n",
    "            error = 0\n",
    "            accuracy = []\n",
    "            for i in range(len(training_data)):\n",
    "                correctness = abs(classifier[i].classify(training_data[i][0]) - training_data[i][1])\n",
    "                accuracy.append(correctness)\n",
    "                w_correctness = weights[i] * correctness\n",
    "                error =  error + w_correctness\n",
    "                \n",
    "            error = error / len(training_data)\n",
    "            if error < best_error:\n",
    "                best_accuracy = accuracy\n",
    "                best_clf = classifier[i]\n",
    "\n",
    "                best_error = error\n",
    "                \n",
    "\n",
    "        return best_clf, best_error, best_accuracy\n",
    "     \n",
    "     \n",
    "    def get_features(self, image_shape):\n",
    "        height = image_shape[0]\n",
    "        width = image_shape[1]\n",
    "        features = []\n",
    "        fi = []\n",
    "        flag = 0\n",
    "        for w in range(1, width+1):\n",
    "            for h in range(1, height+1):\n",
    "                i = 0\n",
    "                if(len(features)==0):\n",
    "                    fi.append([w,h])\n",
    "                while i + w < width:\n",
    "                    j = 0\n",
    "                    if(len(fi)):\n",
    "                        flag = 1\n",
    "                    while j + h < height:\n",
    "                   \n",
    "                        imme = FeaturesComp(i, j, w, h)\n",
    "                        right = FeaturesComp(i+w, j, w, h)\n",
    "                        cur_w = i + 2 * w\n",
    "                        if  cur_w < width: #Horizontally Adjacent\n",
    "                            t = ([right], [imme])\n",
    "                            features.append(t)\n",
    "\n",
    "                        cur_h = j + 2 * h\n",
    "                        bottom = FeaturesComp(i, j+h, w, h)\n",
    "                        if cur_h < height: #Vertically Adjacent\n",
    "                            t = ([imme], [bottom])\n",
    "                            features.append(t)\n",
    "                        \n",
    "                        right_2 = FeaturesComp(i+2*w, j, w, h)\n",
    "                        cur_w = i + 3 * w\n",
    "                        if cur_w < width: #Horizontally Adjacent\n",
    "                            ha = [right_2, imme]\n",
    "                            t = ([right], ha)\n",
    "                            features.append(t)\n",
    "\n",
    "                        bottom_2 = FeaturesComp(i, j+2*h, w, h)\n",
    "                        cur_h = j + 3 * h\n",
    "                        if cur_h < height: #Vertically Adjacent\n",
    "                            va = [bottom_2, imme]\n",
    "                            t = ([bottom], va)\n",
    "                            features.append(t)\n",
    "\n",
    "                       \n",
    "                        bottom_right = FeaturesComp(i+w, j+h, w, h)\n",
    "                        cur_w = i + 2 * w\n",
    "                        if cur_w < width and j + 2 * h < height:\n",
    "                            ibr = [imme, bottom_right]\n",
    "                            t = ([right, bottom], ibr)\n",
    "                            features.append(t)\n",
    "\n",
    "                        j += 1\n",
    "                    i += 1\n",
    "        features = np.array(features)\n",
    "        return features\n",
    "\n",
    "       \n",
    "\n",
    "class Classifier_weak:\n",
    "    def __init__(self, pos, neg, thresh, polarity):\n",
    "        self.pos = pos\n",
    "        self.neg = neg\n",
    "        self.tot = self.pos + self.neg\n",
    "        self.thresh = thresh\n",
    "        self.polarity = polarity\n",
    "    \n",
    "    \n",
    "    def classify(self, x):\n",
    "        feature = lambda ii: sum([pos.compute_feature(ii) for pos in self.pos]) - sum([neg.compute_feature(ii) for neg in self.neg])\n",
    "        pf = self.polarity * feature(x) \n",
    "        if pf < self.polarity * self.thresh:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "def integral_image(image):\n",
    "    h, w = image.shape\n",
    "    inte_img = np.zeros((h, w))\n",
    "    a = np.zeros((h, w))\n",
    "    for i in range(len(image)):\n",
    "        for j in range(len(image[i])):\n",
    "            a[i][j] = image[i][j]\n",
    "            if i >= 1:\n",
    "                a_cur = a[i-1][j] + image[i][j]\n",
    "                a[i][j] = a_cur\n",
    "            \n",
    "            inte_img[i][j] = a[i][j]\n",
    "            \n",
    "            if j >= 1:\n",
    "                inte_cur = inte_img[i][j-1]+a[i][j]\n",
    "                inte_img[i][j] = inte_cur\n",
    "    \n",
    "    return inte_img\n",
    "    \n",
    "class FeaturesComp:\n",
    "    def __init__(self, x, y, width, height):\n",
    "        self.width = width\n",
    "        self.pos = [x,y]\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.height = height\n",
    "    \n",
    "    def compute_feature(self, ii):\n",
    "        f = ii[self.y+self.height][self.x+self.width]\n",
    "        f += ii[self.y][self.x]\n",
    "        f -= ii[self.y+self.height][self.x]\n",
    "        f += ii[self.y][self.x+self.width]\n",
    "        return  f\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder):\n",
    "    files = os.listdir(folder)\n",
    "    files = sorted(files)\n",
    "    images = []\n",
    "    for f in files:\n",
    "        img = cv2.imread(folder+f,0)\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "def preprocess(face_images, nonface_images):\n",
    "    training = []\n",
    "    for i in range(len(face_images)):\n",
    "        training.append(tuple((face_images[i], 1)))\n",
    "    for i in range(len(nonface_images)):\n",
    "        training.append(tuple((nonface_images[i], 0)))\n",
    "    return training\n",
    "    \n",
    "def train_viola(t, train_data, positive_samples, negative_samples):\n",
    "    clf = ViolaJones(T=t)\n",
    "#     clf.train(train_data, positive_samples , negative_samples)\n",
    "#     evaluate(clf, training)\n",
    "#     clf.save(str(t))\n",
    "\n",
    "face_images = load_images('q1_data/train/faces/')\n",
    "positive_samples = len(face_images)\n",
    "nonface_images = load_images('q1_data/train/non_faces/')\n",
    "negative_samples = len(nonface_images)\n",
    "train_data = preprocess(face_images, nonface_images)\n",
    "train_viola(60, train_data, positive_samples, negative_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " confusion matrix \n",
      " [[22146  1427]\n",
      " [  439    33]]\n",
      "\n",
      " accuracy 0.9223955084217093\n"
     ]
    }
   ],
   "source": [
    "def get_metrics(y_pred, y_test):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return cm, accuracy\n",
    "\n",
    "def test_viola(checkpoint, test_images):\n",
    "    clf = ViolaJones.load(checkpoint)\n",
    "    y_preds = []\n",
    "    for i in range(len(test_images)):\n",
    "        y_pred = clf.classify(test_images[i])\n",
    "        y_preds.append(y_pred)\n",
    "    return y_preds\n",
    "\n",
    "def load_testData():\n",
    "    y_gt = []\n",
    "    with open('q1_data/test/gt.csv', 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "\n",
    "        for row in reader:\n",
    "            if(row != ['img', 'label']):\n",
    "                y_gt.append(int(row[1]))\n",
    "    test_images = load_images('q1_data/test/images/')\n",
    "    return test_images, y_gt\n",
    "\n",
    "test_images, y_gt = load_testData()\n",
    "y_preds = test_viola(\"50\", test_images)\n",
    "cm, acc = get_metrics(y_preds,y_gt)\n",
    "print(\"\\n confusion matrix \\n\",cm)\n",
    "print(\"\\n accuracy\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cascade():\n",
    "    def __init__(self, layers):\n",
    "        self.clfs = []\n",
    "        self.layers = layers\n",
    "    \n",
    "    def load(filename):\n",
    "        with open(filename+\".pkl\", 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "\n",
    "    def train(self, training):\n",
    "        pos = []\n",
    "        neg = []\n",
    "        \n",
    "        for data in training:\n",
    "            img = data[0]\n",
    "            lb = data[1]\n",
    "            if lb == 1:\n",
    "                pos.append(data)\n",
    "            if lb == 0:\n",
    "                neg.append(data)\n",
    "        \n",
    "        for num_features in self.layers:\n",
    "            if len(neg) == 0:\n",
    "                print(\"Stopping early.\")\n",
    "                break\n",
    "            false_positives = []   \n",
    "            clf = ViolaJones(T=num_features)\n",
    "            tot = pos+neg\n",
    "            pos_num = len(pos)\n",
    "            neg_num = len(neg)\n",
    "            clf.train(tot, pos_num, neg_num)\n",
    "            self.clfs.append(clf)\n",
    "            num_fakes = 0\n",
    "            for data in neg:\n",
    "                lb = data[1]\n",
    "                if self.classify(lb) == 1:\n",
    "                    false_positives.append(data)\n",
    "                if lb == 0:\n",
    "                    num_fakes += 1\n",
    "                    \n",
    "            neg = false_positives\n",
    "\n",
    "    def classify(self, image):\n",
    "        for clf in self.clfs:\n",
    "            pred_lb = clf.classify(image)\n",
    "            if pred_lb == 0:\n",
    "                return 0\n",
    "        return 1\n",
    "\n",
    "    def save(self, filename):\n",
    "        with open(filename+\".pkl\", 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " confusion matrix \n",
      " [[23424   149]\n",
      " [  471     1]]\n",
      "\n",
      " accuracy 0.9742150135163236\n"
     ]
    }
   ],
   "source": [
    "def train_cascade(layers, train_data, filename=\"cascade\"):\n",
    "    clf = Cascade(layers)\n",
    "    clf.train(train_data)\n",
    "    clf.save(filename)\n",
    "\n",
    "# train_cascade([1, 5, 10, 50], train_data, filename=\"cascade_50\")\n",
    "def test_cascade(test_images,filename=\"cascade\"):\n",
    "    clf = Cascade.load(filename)\n",
    "    y_preds = []\n",
    "    for i in range(len(test_images)):\n",
    "        y_pred = clf.classify(test_images[i])\n",
    "        y_preds.append(y_pred)\n",
    "    return y_preds\n",
    "\n",
    "test_images, y_gt = load_testData()\n",
    "y_preds = test_cascade(test_images, \"cascade\", )\n",
    "cm, acc = get_metrics(y_preds,y_gt)\n",
    "print(\"\\n confusion matrix \\n\",cm)\n",
    "print(\"\\n accuracy\", acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
